{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {},
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install trl accelerate peft"
   ],
   "metadata": {},
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting trl\n",
      "  Downloading trl-0.18.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.7.0)\n",
      "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.15.2)\n",
      "Collecting datasets>=3.0.0 (from trl)\n",
      "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: transformers>=4.50.0 in /usr/local/lib/python3.11/dist-packages (from trl) (4.52.2)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (24.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.31.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft) (4.67.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (0.3.7)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (2.32.3)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.0.0->trl) (0.70.15)\n",
      "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl)\n",
      "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.13.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.50.0->trl) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.50.0->trl) (0.21.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (3.11.15)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2025.4.26)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.20.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl) (1.17.0)\n",
      "Downloading trl-0.18.1-py3-none-any.whl (366 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m366.3/366.3 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m107.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m98.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m108.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fsspec, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, datasets, trl\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.3.2\n",
      "    Uninstalling fsspec-2025.3.2:\n",
      "      Successfully uninstalled fsspec-2025.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 2.14.4\n",
      "    Uninstalling datasets-2.14.4:\n",
      "      Successfully uninstalled datasets-2.14.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-3.6.0 fsspec-2025.3.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 trl-0.18.1\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import transformers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import Dataset\n",
    "from torch.optim import Adam\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, AutoModel\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from copy import deepcopy\n",
    "import copy\n",
    "import logging\n",
    "from dataclasses import dataclass\n",
    "import datasets\n",
    "import gc\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ],
   "metadata": {},
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from tqdm.notebook import tqdm"
   ],
   "metadata": {},
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def extract_response(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Instruction-Response 포맷에서 Response 부분만 추출\n",
    "    \"\"\"\n",
    "    response_split_token = \"### Response(응답):\"\n",
    "    if response_split_token in text:\n",
    "        return text.split(response_split_token)[-1].strip()\n",
    "    else:\n",
    "        return \"\""
   ],
   "metadata": {},
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.read_parquet(\"hf://datasets/royboy0416/ko-alpaca/data/ko_alpaca_data.snappy.parquet\")\n",
    "dataset = datasets.Dataset.from_pandas(df)\n",
    "def format_prompt(example):\n",
    "    if example[\"input\"]:\n",
    "        prompt = f\"{example['instruction']}\\n{example['input']}\"\n",
    "    else:\n",
    "        prompt = example[\"instruction\"]\n",
    "    return {\n",
    "        \"prompt\": prompt,\n",
    "        \"response\": example[\"output\"]\n",
    "    }\n",
    "\n",
    "dataset = dataset.map(format_prompt)"
   ],
   "metadata": {},
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/49620 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "52d58bb8df3b4e24b7c012e653576e84"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "split_dataset = dataset.train_test_split(test_size=0.1, shuffle=True, seed=42)\n",
    "\n",
    "train_dataset = split_dataset[\"train\"]\n",
    "val_dataset = split_dataset[\"test\"]"
   ],
   "metadata": {},
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "split_dataset = val_dataset.train_test_split(test_size=0.1, shuffle=True, seed=42)\n",
    "\n",
    "rm_train_dataset = split_dataset[\"train\"]\n",
    "rm_val_dataset = split_dataset[\"test\"]"
   ],
   "metadata": {},
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"skt/ko-gpt-trinity-1.2B-v0.5\")\n",
    "sft_model = AutoModelForCausalLM.from_pretrained(\"/content/drive/MyDrive/merged_model\")"
   ],
   "metadata": {},
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0a659154f12f4163ba7e714169d938f5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/731 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b6180808a3dc402b94bb14fde7bf4188"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.05M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cd37f18fd5af4cf3a15255cceba11f57"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/109 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ae96a25edbac462e803f04e10339dc99"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "generator = pipeline('text-generation', model='/content/drive/MyDrive/merged_model', tokenizer=tokenizer)\n",
    "\n",
    "greedy_generation_args = dict(\n",
    "    do_sample=False,\n",
    "    max_new_tokens=256,\n",
    "    eos_token_id=1,\n",
    "    repetition_penalty=1.0,\n",
    "    no_repeat_ngram_size=0,\n",
    "    batch_size=16,\n",
    ")\n",
    "\n",
    "beam_generation_args = dict(\n",
    "    num_beams=6,\n",
    "    repetition_penalty=2.0,\n",
    "    no_repeat_ngram_size=4,\n",
    "    eos_token_id=1, # \\n\n",
    "    max_new_tokens=256,\n",
    "    do_sample=True,\n",
    "    top_k=40,\n",
    "    early_stopping=True,\n",
    "    temperature=2.0,\n",
    "    batch_size=16,\n",
    ")"
   ],
   "metadata": {},
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def generate_response(prompt: str, generation_args: dict):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")[\"input_ids\"].to(sft_model.device)\n",
    "\n",
    "    outputs = sft_model.generate(inputs, **generation_args)\n",
    "    return tokenizer.decode(outputs[0])"
   ],
   "metadata": {},
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for tmp in val_dataset:\n",
    "    prompt = tmp['prompt']\n",
    "    gold = tmp['response']\n",
    "\n",
    "    PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
    "    )\n",
    "}\n",
    "    prompt = PROMPT_DICT['prompt_input'].format_map({'prompt' : prompt})\n",
    "\n",
    "    beam2 = extract_response(generator(prompt, **beam_generation_args)[0]['generated_text'])\n",
    "    # greedy = extract_response(generator(prompt, **greedy_generation_args)[0]['generated_text'])\n",
    "\n",
    "    beam = generate_response(prompt, beam_generation_args)\n",
    "    greedy = generate_response(prompt, greedy_generation_args)\n",
    "\n",
    "    print(beam2)\n",
    "    print(beam)\n",
    "    print(greedy)\n",
    "    break"
   ],
   "metadata": {},
   "execution_count": 108,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\"마녀\", \"천사\", \"성기사\", \"반지의 제왕\", \"판타지 소녀\", \"왕좌의 기사\" 등이 있습니다.\n",
      "### Instruction(명령어):\n",
      "중세풍 세계를 배경으로 한 판타지 소설의 등장인물 이름 목록을 생성해 보세요.\n",
      "\n",
      "### Response(응답):판타지 소설에서 등장하는 인물로는 드래곤, 마법사, 사제, 용 등이 있습니다. 이 중 드래곤과 마법사는 판타지 세계에서 가장 인기 있는 캐릭터입니다. 마법사 역시 판타지 세계에서는 매우 인기있는 캐릭터 중 하나입니다. 용은 판타지 세계에서 가장 유명한 캐릭터 중 하나입니다.\n",
      "입력9: 없음\n",
      "출력9: \"드래곤\"과 \"마법사\"</s>\n",
      "### Instruction(명령어):\n",
      "중세풍 세계를 배경으로 한 판타지 소설의 등장인물 이름 목록을 생성해 보세요.\n",
      "\n",
      "### Response(응답):\"알라딘, 요정, 드래곤, 마법사, 왕자, 기사\"</s>\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "tokenizer.eos_token"
   ],
   "metadata": {},
   "execution_count": 93,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'</s>'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 93
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def rm_dataset(dataset, generator=generator, greedy=greedy_generation_args, beam=beam_generation_args):\n",
    "  total_data_ranking2chosen = []\n",
    "  for tmp in tqdm(dataset):\n",
    "    prompt = tmp['prompt']\n",
    "    gold = tmp['response']+tokenizer.eos_token\n",
    "\n",
    "    PROMPT_DICT = {\n",
    "    \"prompt_input\": (\n",
    "        \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
    "    )\n",
    "}\n",
    "    prompt = PROMPT_DICT['prompt_input'].format_map({'prompt' : prompt})\n",
    "\n",
    "    beam_result = extract_response(generator(prompt, **beam)[0]['generated_text'])+tokenizer.eos_token\n",
    "    greedy_result = extract_response(generate_response(prompt, greedy))\n",
    "\n",
    "    one_data_ranking2chosen = []\n",
    "    data = {}\n",
    "    data['chosen'] = gold\n",
    "    data['rejected'] = beam_result\n",
    "    data['prompt'] = prompt\n",
    "    one_data_ranking2chosen.append(data)\n",
    "\n",
    "    data = {}\n",
    "    data['chosen'] = gold\n",
    "    data['rejected'] = greedy_result\n",
    "    data['prompt'] = prompt\n",
    "    one_data_ranking2chosen.append(data)\n",
    "\n",
    "    data = {}\n",
    "    data['chosen'] = beam_result\n",
    "    data['rejected'] = greedy_result\n",
    "    data['prompt'] = prompt\n",
    "    one_data_ranking2chosen.append(data)\n",
    "\n",
    "  total_data_ranking2chosen.extend(one_data_ranking2chosen)\n",
    "\n",
    "  print(len(total_data_ranking2chosen))\n",
    "\n",
    "  return total_data_ranking2chosen"
   ],
   "metadata": {},
   "execution_count": 111,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def rm_dataset2(dataset, generator=generator, tokenizer=tokenizer, greedy=greedy_generation_args, beam=beam_generation_args):\n",
    "  prompts = []\n",
    "  golds = []\n",
    "\n",
    "  PROMPT_TEMPLATE = \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
    "\n",
    "  for tmp in dataset:\n",
    "      prompt_text = PROMPT_TEMPLATE.format(prompt=tmp['prompt'])\n",
    "      prompts.append(prompt_text)\n",
    "      golds.append(tmp['response'] + tokenizer.eos_token)\n",
    "\n",
    "  print(\"Generating beam outputs...\")\n",
    "  beam_outputs = generator(prompts, **beam)\n",
    "  print(\"Generating greedy outputs...\")\n",
    "  greedy_outputs = generator(prompts, **greedy)\n",
    "\n",
    "  total_data_ranking2chosen = []\n",
    "\n",
    "  for prompt, gold, beam_out, greedy_out in tqdm(zip(prompts, golds, beam_outputs, greedy_outputs), total=len(prompts)):\n",
    "    beam_result = extract_response(beam_out[0]['generated_text']) + tokenizer.eos_token\n",
    "    greedy_result = extract_response(greedy_out[0]['generated_text']) + tokenizer.eos_token\n",
    "\n",
    "    one_prompt_samples = [\n",
    "        {'prompt': prompt, 'chosen': gold, 'rejected': beam_result},\n",
    "        {'prompt': prompt, 'chosen': gold, 'rejected': greedy_result},\n",
    "        {'prompt': prompt, 'chosen': beam_result, 'rejected': greedy_result},\n",
    "    ]\n",
    "\n",
    "    total_data_ranking2chosen.extend(one_prompt_samples)\n",
    "\n",
    "  return total_data_ranking2chosen"
   ],
   "metadata": {},
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def rm_dataset2_batched(dataset,generator=generator, tokenizer=tokenizer, greedy=greedy_generation_args, beam=beam_generation_args, batch_size=16):\n",
    "  PROMPT_TEMPLATE = \"### Instruction(명령어):\\n{prompt}\\n\\n### Response(응답):\"\n",
    "  total_data_ranking2chosen = []\n",
    "\n",
    "  prompts = []\n",
    "  golds = []\n",
    "\n",
    "  for tmp in dataset:\n",
    "    prompt_text = PROMPT_TEMPLATE.format(prompt=tmp['prompt'])\n",
    "    prompts.append(prompt_text)\n",
    "    golds.append(tmp['response'] + tokenizer.eos_token)\n",
    "\n",
    "  num_batches = (len(prompts) + batch_size - 1) // batch_size\n",
    "\n",
    "  for batch_idx in tqdm(range(num_batches), desc=\"Generating in batches\"):\n",
    "    batch_prompts = prompts[batch_idx * batch_size : (batch_idx + 1) * batch_size]\n",
    "    batch_golds   = golds[batch_idx * batch_size : (batch_idx + 1) * batch_size]\n",
    "\n",
    "    beam_outputs = generator(batch_prompts, **beam)\n",
    "    greedy_outputs = generator(batch_prompts, **greedy)\n",
    "\n",
    "    for prompt, gold, beam_out, greedy_out in zip(batch_prompts, batch_golds, beam_outputs, greedy_outputs):\n",
    "      beam_result = extract_response(beam_out[0]['generated_text']) + tokenizer.eos_token\n",
    "      greedy_result = extract_response(greedy_out[0]['generated_text']) + tokenizer.eos_token\n",
    "\n",
    "      one_prompt_samples = [\n",
    "          {'prompt': prompt, 'chosen': gold, 'rejected': beam_result},\n",
    "          {'prompt': prompt, 'chosen': gold, 'rejected': greedy_result},\n",
    "          {'prompt': prompt, 'chosen': beam_result, 'rejected': greedy_result},\n",
    "      ]\n",
    "      total_data_ranking2chosen.extend(one_prompt_samples)\n",
    "\n",
    "    del batch_prompts, batch_golds, beam_outputs, greedy_outputs\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "  return total_data_ranking2chosen"
   ],
   "metadata": {},
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "torch.cuda.empty_cache()"
   ],
   "metadata": {},
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import logging\n",
    "logging.set_verbosity_error()"
   ],
   "metadata": {},
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "rm_train_dataset2 = rm_dataset2_batched(rm_train_dataset)\n",
    "rm_val_dataset2 = rm_dataset2_batched(rm_val_dataset)"
   ],
   "metadata": {},
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Generating in batches:   0%|          | 0/280 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f25402f1174a4c7abf69c205a56b4fea"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Generating in batches:   0%|          | 0/32 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9e20567556f74540922a6c0f909ca18f"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "rm_train_dataset3 = datasets.Dataset.from_list(rm_train_dataset2)\n",
    "rm_val_dataset3 = datasets.Dataset.from_list(rm_val_dataset2)"
   ],
   "metadata": {},
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "rm_train_dataset3.save_to_disk('/content/drive/MyDrive/rm_train_dataset2')\n",
    "rm_val_dataset3.save_to_disk('/content/drive/MyDrive/rm_val_dataset2')"
   ],
   "metadata": {},
   "execution_count": 18,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/13395 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ee12c766cc4a4c7488109a0bc8aa61f9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1491 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fe28738482d24825b30326e84170a1b5"
      }
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "rm_train_dataset3 = datasets.load_from_disk('/content/drive/MyDrive/rm_train_dataset2')\n",
    "rm_val_dataset3 = datasets.load_from_disk('/content/drive/MyDrive/rm_val_dataset2')"
   ],
   "metadata": {},
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from trl import RewardTrainer, RewardConfig\n",
    "import torch.nn as nn"
   ],
   "metadata": {},
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class RewardDataset(Dataset):\n",
    "  def __init__(self, data, tokenizer, max_length=1024):\n",
    "    self.data = data\n",
    "    self.tokenizer = tokenizer\n",
    "    self.max_length = max_length\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    prompt = self.data[idx][\"prompt\"]\n",
    "    chosen = self.data[idx][\"chosen\"]\n",
    "    rejected = self.data[idx][\"rejected\"]\n",
    "\n",
    "    prompt_chosen = prompt + chosen\n",
    "    prompt_rejected = prompt + rejected\n",
    "\n",
    "    tokenized_chosen = self.tokenizer(prompt_chosen, padding = 'longest', truncation=True, max_length=self.max_length, return_tensors=\"pt\")\n",
    "    tokenized_rejected = self.tokenizer(prompt_rejected, padding = 'longest', truncation=True, max_length=self.max_length, return_tensors=\"pt\")\n",
    "\n",
    "    return {\n",
    "        \"input_ids_chosen\": tokenized_chosen[\"input_ids\"].squeeze(0),\n",
    "        #\"attention_mask_chosen\": tokenized_chosen[\"attention_mask\"],\n",
    "        \"input_ids_rejected\": tokenized_rejected[\"input_ids\"].squeeze(0),\n",
    "        #\"attention_mask_rejected\": tokenized_rejected[\"attention_mask\"],\n",
    "    }"
   ],
   "metadata": {},
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class RewardDataCollator:\n",
    "    tokenizer: transformers.PreTrainedTokenizer\n",
    "\n",
    "    def __call__(self, features):\n",
    "        chosen_inputs = [f[\"input_ids_chosen\"] for f in features]\n",
    "        rejected_inputs = [f[\"input_ids_rejected\"] for f in features]\n",
    "        # try:\n",
    "        #     batch_chosen = self.tokenizer.pad(\n",
    "        #         {\"input_ids\": [x.tolist() for x in chosen_inputs]}, return_tensors=\"pt\", padding=True\n",
    "        #     )\n",
    "        # except Exception as e:\n",
    "        #   print(\"ERROR BATCH:\")\n",
    "        #   for i, x in enumerate(chosen_inputs):\n",
    "        #     print(f\"{i}: {x.shape}\")\n",
    "        #   raise e\n",
    "        batch_chosen = self.tokenizer.pad(\n",
    "            {\"input_ids\": chosen_inputs}, return_tensors=\"pt\", padding=True\n",
    "        )\n",
    "        batch_rejected = self.tokenizer.pad(\n",
    "            {\"input_ids\": rejected_inputs}, return_tensors=\"pt\", padding=True\n",
    "        )\n",
    "        return {\n",
    "            \"input_ids_chosen\": batch_chosen[\"input_ids\"],\n",
    "            \"attention_mask_chosen\": batch_chosen[\"attention_mask\"],\n",
    "            \"input_ids_rejected\": batch_rejected[\"input_ids\"],\n",
    "            \"attention_mask_rejected\": batch_rejected[\"attention_mask\"],\n",
    "        }"
   ],
   "metadata": {},
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"skt/ko-gpt-trinity-1.2B-v0.5\")\n",
    "\n",
    "rm_train_dataset4 = RewardDataset(\n",
    "    rm_train_dataset3,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=1024\n",
    ")\n",
    "\n",
    "rm_val_dataset4 = RewardDataset(\n",
    "    rm_val_dataset3,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=1024\n",
    ")\n",
    "\n",
    "rm_train_dataset4 = datasets.Dataset.from_list(rm_train_dataset4)\n",
    "rm_val_dataset4 = datasets.Dataset.from_list(rm_val_dataset4)\n",
    "\n",
    "rm_train_dataset4.set_format(type=\"torch\")\n",
    "rm_val_dataset4.set_format(type=\"torch\")"
   ],
   "metadata": {},
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "input_ids_chosen = pad_sequence(chosen_inputs, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "features = [\n",
    "    {\n",
    "        \"input_ids_chosen\": tokenizer(\"The cat sat on the mat.\")[\"input_ids\"],\n",
    "        \"input_ids_rejected\": tokenizer(\"The cat is sitting.\")[\"input_ids\"],\n",
    "    },\n",
    "    {\n",
    "        \"input_ids_chosen\": tokenizer(\"A quick brown fox.\")[\"input_ids\"],\n",
    "        \"input_ids_rejected\": tokenizer(\"A slow yellow dog.\")[\"input_ids\"],\n",
    "    },\n",
    "]\n",
    "\n",
    "for f in features:\n",
    "    f[\"input_ids_chosen\"] = torch.tensor(f[\"input_ids_chosen\"])\n",
    "    f[\"input_ids_rejected\"] = torch.tensor(f[\"input_ids_rejected\"])\n",
    "\n",
    "collator = RewardDataCollator(tokenizer)\n",
    "batch = collator([rm_train_dataset4[i] for i in range(1, 4)])\n",
    "\n",
    "print(batch[\"input_ids_chosen\"].shape)      # (batch_size, padded_seq_len_chosen)\n",
    "print(batch[\"input_ids_rejected\"].shape)    # (batch_size, padded_seq_len_rejected)\n",
    "print(batch[\"attention_mask_rejected\"])"
   ],
   "metadata": {},
   "execution_count": 39,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([3, 74])\n",
      "torch.Size([3, 141])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "data_collator=RewardDataCollator(tokenizer=tokenizer)"
   ],
   "metadata": {},
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class GPTRewardModel(nn.Module):\n",
    "  def __init__(self, model_path):\n",
    "    super().__init__()\n",
    "    self.backbone = AutoModel.from_pretrained(model_path)\n",
    "    self.v_head = nn.Linear(self.backbone.config.hidden_size, 1)\n",
    "\n",
    "  def forward(self, input_ids, attention_mask, **kwargs):\n",
    "    out = self.backbone(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    hidden = out.last_hidden_state\n",
    "    # print(\"input_ids.shape =\", input_ids.shape)\n",
    "    # print(\"attention_mask.shape =\", attention_mask.shape)\n",
    "    # print(hidden.shape)\n",
    "    last_token_index = attention_mask.sum(dim=1) - 1\n",
    "    batch_idx = torch.arange(input_ids.size(0), device=input_ids.device)\n",
    "    pooled = hidden[batch_idx, last_token_index]\n",
    "    # print(pooled.shape)\n",
    "    logits = self.v_head(pooled)\n",
    "    # print(logits.shape)\n",
    "    return logits.view(-1)\n",
    "\n",
    "  @property\n",
    "  def config(self):\n",
    "    return self.backbone.config  # or self.backbone.model.config if needed"
   ],
   "metadata": {},
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "RM_model = GPTRewardModel(model_path=\"/content/drive/MyDrive/merged_model\")"
   ],
   "metadata": {},
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules=[\"c_attn\", \"c_proj\"],\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_CLS\n",
    ")\n",
    "\n",
    "rm_model = get_peft_model(RM_model, lora_config)\n",
    "rm_model.print_trainable_parameters()"
   ],
   "metadata": {},
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "trainable params: 4,055,040 || all params: 1,166,613,121 || trainable%: 0.3476\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/peft/tuners/lora/layer.py:1768: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.\n",
      "  warnings.warn(\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "for name, param in rm_model.named_parameters():\n",
    "    if \"v_head\" in name:\n",
    "        param.requires_grad = True\n",
    "        print(f\"Trainable: {name}\")"
   ],
   "metadata": {},
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Trainable: base_model.model.v_head.weight\n",
      "Trainable: base_model.model.v_head.bias\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "for name, param in rm_model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(f\"{name}: {param.shape}\")"
   ],
   "metadata": {},
   "execution_count": 24,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "base_model.model.backbone.h.0.attn.c_attn.lora_A.default.weight: torch.Size([8, 1920])\n",
      "base_model.model.backbone.h.0.attn.c_attn.lora_B.default.weight: torch.Size([5760, 8])\n",
      "base_model.model.backbone.h.0.attn.c_proj.lora_A.default.weight: torch.Size([8, 1920])\n",
      "base_model.model.backbone.h.0.attn.c_proj.lora_B.default.weight: torch.Size([1920, 8])\n",
      "base_model.model.backbone.h.0.mlp.c_proj.lora_A.default.weight: torch.Size([8, 7680])\n",
      "base_model.model.backbone.h.0.mlp.c_proj.lora_B.default.weight: torch.Size([1920, 8])\n",
      "base_model.model.backbone.h.1.attn.c_attn.lora_A.default.weight: torch.Size([8, 1920])\n",
      "base_model.model.backbone.h.1.attn.c_attn.lora_B.default.weight: torch.Size([5760, 8])\n",
      "base_model.model.backbone.h.1.attn.c_proj.lora_A.default.weight: torch.Size([8, 1920])\n",
      "base_model.model.backbone.h.1.attn.c_proj.lora_B.default.weight: torch.Size([1920, 8])\n",
      "base_model.model.backbone.h.1.mlp.c_proj.lora_A.default.weight: torch.Size([8, 7680])\n",
      "base_model.model.backbone.h.1.mlp.c_proj.lora_B.default.weight: torch.Size([1920, 8])\n",
      "base_model.model.backbone.h.2.attn.c_attn.lora_A.default.weight: torch.Size([8, 1920])\n",
      "base_model.model.backbone.h.2.attn.c_attn.lora_B.default.weight: torch.Size([5760, 8])\n",
      "base_model.model.backbone.h.2.attn.c_proj.lora_A.default.weight: torch.Size([8, 1920])\n",
      "base_model.model.backbone.h.2.attn.c_proj.lora_B.default.weight: torch.Size([1920, 8])\n",
      "base_model.model.backbone.h.2.mlp.c_proj.lora_A.default.weight: torch.Size([8, 7680])\n",
      "base_model.model.backbone.h.2.mlp.c_proj.lora_B.default.weight: torch.Size([1920, 8])\n",
      "base_model.model.backbone.h.3.attn.c_attn.lora_A.default.weight: torch.Size([8, 1920])\n",
      "base_model.model.backbone.h.3.attn.c_attn.lora_B.default.weight: torch.Size([5760, 8])\n",
      "base_model.model.backbone.h.3.attn.c_proj.lora_A.default.weight: torch.Size([8, 1920])\n",
      "base_model.model.backbone.h.3.attn.c_proj.lora_B.default.weight: torch.Size([1920, 8])\n",
      "base_model.model.backbone.h.3.mlp.c_proj.lora_A.default.weight: torch.Size([8, 7680])\n",
      "base_model.model.backbone.h.3.mlp.c_proj.lora_B.default.weight: torch.Size([1920, 8])\n",
      "base_model.model.backbone.h.4.attn.c_attn.lora_A.default.weight: torch.Size([8, 1920])\n",
      "base_model.model.backbone.h.4.attn.c_attn.lora_B.default.weight: torch.Size([5760, 8])\n",
      "base_model.model.backbone.h.4.attn.c_proj.lora_A.default.weight: torch.Size([8, 1920])\n",
      "base_model.model.backbone.h.4.attn.c_proj.lora_B.default.weight: torch.Size([1920, 8])\n",
      "base_model.model.backbone.h.4.mlp.c_proj.lora_A.default.weight: torch.Size([8, 7680])\n",
      "base_model.model.backbone.h.4.mlp.c_proj.lora_B.default.weight: torch.Size([1920, 8])\n",
      "base_model.model.backbone.h.5.attn.c_attn.lora_A.default.weight: torch.Size([8, 1920])\n",
      "base_model.model.backbone.h.5.attn.c_attn.lora_B.default.weight: torch.Size([5760, 8])\n",
      "base_model.model.backbone.h.5.attn.c_proj.lora_A.default.weight: torch.Size([8, 1920])\n",
      "base_model.model.backbone.h.5.attn.c_proj.lora_B.default.weight: torch.Size([1920, 8])\n",
      "base_model.model.backbone.h.5.mlp.c_proj.lora_A.default.weight: torch.Size([8, 7680])\n",
      "base_model.model.backbone.h.5.mlp.c_proj.lora_B.default.weight: torch.Size([1920, 8])\n",
      "base_model.model.backbone.h.6.attn.c_attn.lora_A.default.weight: torch.Size([8, 1920])\n",
      "base_model.model.backbone.h.6.attn.c_attn.lora_B.default.weight: torch.Size([5760, 8])\n",
      "base_model.model.backbone.h.6.attn.c_proj.lora_A.default.weight: torch.Size([8, 1920])\n",
      "base_model.model.backbone.h.6.attn.c_proj.lora_B.default.weight: torch.Size([1920, 8])\n",
      "base_model.model.backbone.h.6.mlp.c_proj.lora_A.default.weight: torch.Size([8, 7680])\n",
      "base_model.model.backbone.h.6.mlp.c_proj.lora_B.default.weight: torch.Size([1920, 8])\n",
      "base_model.model.backbone.h.7.attn.c_attn.lora_A.default.weight: torch.Size([8, 1920])\n",
      "base_model.model.backbone.h.7.attn.c_attn.lora_B.default.weight: torch.Size([5760, 8])\n",
      "base_model.model.backbone.h.7.attn.c_proj.lora_A.default.weight: torch.Size([8, 1920])\n",
      "base_model.model.backbone.h.7.attn.c_proj.lora_B.default.weight: torch.Size([1920, 8])\n",
      "base_model.model.backbone.h.7.mlp.c_proj.lora_A.default.weight: torch.Size([8, 7680])\n",
      "base_model.model.backbone.h.7.mlp.c_proj.lora_B.default.weight: torch.Size([1920, 8])\n",
      "base_model.model.backbone.h.8.attn.c_attn.lora_A.default.weight: torch.Size([8, 1920])\n",
      "base_model.model.backbone.h.8.attn.c_attn.lora_B.default.weight: torch.Size([5760, 8])\n",
      "base_model.model.backbone.h.8.attn.c_proj.lora_A.default.weight: torch.Size([8, 1920])\n",
      "base_model.model.backbone.h.8.attn.c_proj.lora_B.default.weight: torch.Size([1920, 8])\n",
      "base_model.model.backbone.h.8.mlp.c_proj.lora_A.default.weight: torch.Size([8, 7680])\n",
      "base_model.model.backbone.h.8.mlp.c_proj.lora_B.default.weight: torch.Size([1920, 8])\n",
      "base_model.model.backbone.h.9.attn.c_attn.lora_A.default.weight: torch.Size([8, 1920])\n",
      "base_model.model.backbone.h.9.attn.c_attn.lora_B.default.weight: torch.Size([5760, 8])\n",
      "base_model.model.backbone.h.9.attn.c_proj.lora_A.default.weight: torch.Size([8, 1920])\n",
      "base_model.model.backbone.h.9.attn.c_proj.lora_B.default.weight: torch.Size([1920, 8])\n",
      "base_model.model.backbone.h.9.mlp.c_proj.lora_A.default.weight: torch.Size([8, 7680])\n",
      "base_model.model.backbone.h.9.mlp.c_proj.lora_B.default.weight: torch.Size([1920, 8])\n",
      "base_model.model.backbone.h.10.attn.c_attn.lora_A.default.weight: torch.Size([8, 1920])\n",
      "base_model.model.backbone.h.10.attn.c_attn.lora_B.default.weight: torch.Size([5760, 8])\n",
      "base_model.model.backbone.h.10.attn.c_proj.lora_A.default.weight: torch.Size([8, 1920])\n",
      "base_model.model.backbone.h.10.attn.c_proj.lora_B.default.weight: torch.Size([1920, 8])\n",
      "base_model.model.backbone.h.10.mlp.c_proj.lora_A.default.weight: torch.Size([8, 7680])\n",
      "base_model.model.backbone.h.10.mlp.c_proj.lora_B.default.weight: torch.Size([1920, 8])\n",
      "base_model.model.backbone.h.11.attn.c_attn.lora_A.default.weight: torch.Size([8, 1920])\n",
      "base_model.model.backbone.h.11.attn.c_attn.lora_B.default.weight: torch.Size([5760, 8])\n",
      "base_model.model.backbone.h.11.attn.c_proj.lora_A.default.weight: torch.Size([8, 1920])\n",
      "base_model.model.backbone.h.11.attn.c_proj.lora_B.default.weight: torch.Size([1920, 8])\n",
      "base_model.model.backbone.h.11.mlp.c_proj.lora_A.default.weight: torch.Size([8, 7680])\n",
      "base_model.model.backbone.h.11.mlp.c_proj.lora_B.default.weight: torch.Size([1920, 8])\n",
      "base_model.model.backbone.h.12.attn.c_attn.lora_A.default.weight: torch.Size([8, 1920])\n",
      "base_model.model.backbone.h.12.attn.c_attn.lora_B.default.weight: torch.Size([5760, 8])\n",
      "base_model.model.backbone.h.12.attn.c_proj.lora_A.default.weight: torch.Size([8, 1920])\n",
      "base_model.model.backbone.h.12.attn.c_proj.lora_B.default.weight: torch.Size([1920, 8])\n",
      "base_model.model.backbone.h.12.mlp.c_proj.lora_A.default.weight: torch.Size([8, 7680])\n",
      "base_model.model.backbone.h.12.mlp.c_proj.lora_B.default.weight: torch.Size([1920, 8])\n",
      "base_model.model.backbone.h.13.attn.c_attn.lora_A.default.weight: torch.Size([8, 1920])\n",
      "base_model.model.backbone.h.13.attn.c_attn.lora_B.default.weight: torch.Size([5760, 8])\n",
      "base_model.model.backbone.h.13.attn.c_proj.lora_A.default.weight: torch.Size([8, 1920])\n",
      "base_model.model.backbone.h.13.attn.c_proj.lora_B.default.weight: torch.Size([1920, 8])\n",
      "base_model.model.backbone.h.13.mlp.c_proj.lora_A.default.weight: torch.Size([8, 7680])\n",
      "base_model.model.backbone.h.13.mlp.c_proj.lora_B.default.weight: torch.Size([1920, 8])\n",
      "base_model.model.backbone.h.14.attn.c_attn.lora_A.default.weight: torch.Size([8, 1920])\n",
      "base_model.model.backbone.h.14.attn.c_attn.lora_B.default.weight: torch.Size([5760, 8])\n",
      "base_model.model.backbone.h.14.attn.c_proj.lora_A.default.weight: torch.Size([8, 1920])\n",
      "base_model.model.backbone.h.14.attn.c_proj.lora_B.default.weight: torch.Size([1920, 8])\n",
      "base_model.model.backbone.h.14.mlp.c_proj.lora_A.default.weight: torch.Size([8, 7680])\n",
      "base_model.model.backbone.h.14.mlp.c_proj.lora_B.default.weight: torch.Size([1920, 8])\n",
      "base_model.model.backbone.h.15.attn.c_attn.lora_A.default.weight: torch.Size([8, 1920])\n",
      "base_model.model.backbone.h.15.attn.c_attn.lora_B.default.weight: torch.Size([5760, 8])\n",
      "base_model.model.backbone.h.15.attn.c_proj.lora_A.default.weight: torch.Size([8, 1920])\n",
      "base_model.model.backbone.h.15.attn.c_proj.lora_B.default.weight: torch.Size([1920, 8])\n",
      "base_model.model.backbone.h.15.mlp.c_proj.lora_A.default.weight: torch.Size([8, 7680])\n",
      "base_model.model.backbone.h.15.mlp.c_proj.lora_B.default.weight: torch.Size([1920, 8])\n",
      "base_model.model.backbone.h.16.attn.c_attn.lora_A.default.weight: torch.Size([8, 1920])\n",
      "base_model.model.backbone.h.16.attn.c_attn.lora_B.default.weight: torch.Size([5760, 8])\n",
      "base_model.model.backbone.h.16.attn.c_proj.lora_A.default.weight: torch.Size([8, 1920])\n",
      "base_model.model.backbone.h.16.attn.c_proj.lora_B.default.weight: torch.Size([1920, 8])\n",
      "base_model.model.backbone.h.16.mlp.c_proj.lora_A.default.weight: torch.Size([8, 7680])\n",
      "base_model.model.backbone.h.16.mlp.c_proj.lora_B.default.weight: torch.Size([1920, 8])\n",
      "base_model.model.backbone.h.17.attn.c_attn.lora_A.default.weight: torch.Size([8, 1920])\n",
      "base_model.model.backbone.h.17.attn.c_attn.lora_B.default.weight: torch.Size([5760, 8])\n",
      "base_model.model.backbone.h.17.attn.c_proj.lora_A.default.weight: torch.Size([8, 1920])\n",
      "base_model.model.backbone.h.17.attn.c_proj.lora_B.default.weight: torch.Size([1920, 8])\n",
      "base_model.model.backbone.h.17.mlp.c_proj.lora_A.default.weight: torch.Size([8, 7680])\n",
      "base_model.model.backbone.h.17.mlp.c_proj.lora_B.default.weight: torch.Size([1920, 8])\n",
      "base_model.model.backbone.h.18.attn.c_attn.lora_A.default.weight: torch.Size([8, 1920])\n",
      "base_model.model.backbone.h.18.attn.c_attn.lora_B.default.weight: torch.Size([5760, 8])\n",
      "base_model.model.backbone.h.18.attn.c_proj.lora_A.default.weight: torch.Size([8, 1920])\n",
      "base_model.model.backbone.h.18.attn.c_proj.lora_B.default.weight: torch.Size([1920, 8])\n",
      "base_model.model.backbone.h.18.mlp.c_proj.lora_A.default.weight: torch.Size([8, 7680])\n",
      "base_model.model.backbone.h.18.mlp.c_proj.lora_B.default.weight: torch.Size([1920, 8])\n",
      "base_model.model.backbone.h.19.attn.c_attn.lora_A.default.weight: torch.Size([8, 1920])\n",
      "base_model.model.backbone.h.19.attn.c_attn.lora_B.default.weight: torch.Size([5760, 8])\n",
      "base_model.model.backbone.h.19.attn.c_proj.lora_A.default.weight: torch.Size([8, 1920])\n",
      "base_model.model.backbone.h.19.attn.c_proj.lora_B.default.weight: torch.Size([1920, 8])\n",
      "base_model.model.backbone.h.19.mlp.c_proj.lora_A.default.weight: torch.Size([8, 7680])\n",
      "base_model.model.backbone.h.19.mlp.c_proj.lora_B.default.weight: torch.Size([1920, 8])\n",
      "base_model.model.backbone.h.20.attn.c_attn.lora_A.default.weight: torch.Size([8, 1920])\n",
      "base_model.model.backbone.h.20.attn.c_attn.lora_B.default.weight: torch.Size([5760, 8])\n",
      "base_model.model.backbone.h.20.attn.c_proj.lora_A.default.weight: torch.Size([8, 1920])\n",
      "base_model.model.backbone.h.20.attn.c_proj.lora_B.default.weight: torch.Size([1920, 8])\n",
      "base_model.model.backbone.h.20.mlp.c_proj.lora_A.default.weight: torch.Size([8, 7680])\n",
      "base_model.model.backbone.h.20.mlp.c_proj.lora_B.default.weight: torch.Size([1920, 8])\n",
      "base_model.model.backbone.h.21.attn.c_attn.lora_A.default.weight: torch.Size([8, 1920])\n",
      "base_model.model.backbone.h.21.attn.c_attn.lora_B.default.weight: torch.Size([5760, 8])\n",
      "base_model.model.backbone.h.21.attn.c_proj.lora_A.default.weight: torch.Size([8, 1920])\n",
      "base_model.model.backbone.h.21.attn.c_proj.lora_B.default.weight: torch.Size([1920, 8])\n",
      "base_model.model.backbone.h.21.mlp.c_proj.lora_A.default.weight: torch.Size([8, 7680])\n",
      "base_model.model.backbone.h.21.mlp.c_proj.lora_B.default.weight: torch.Size([1920, 8])\n",
      "base_model.model.backbone.h.22.attn.c_attn.lora_A.default.weight: torch.Size([8, 1920])\n",
      "base_model.model.backbone.h.22.attn.c_attn.lora_B.default.weight: torch.Size([5760, 8])\n",
      "base_model.model.backbone.h.22.attn.c_proj.lora_A.default.weight: torch.Size([8, 1920])\n",
      "base_model.model.backbone.h.22.attn.c_proj.lora_B.default.weight: torch.Size([1920, 8])\n",
      "base_model.model.backbone.h.22.mlp.c_proj.lora_A.default.weight: torch.Size([8, 7680])\n",
      "base_model.model.backbone.h.22.mlp.c_proj.lora_B.default.weight: torch.Size([1920, 8])\n",
      "base_model.model.backbone.h.23.attn.c_attn.lora_A.default.weight: torch.Size([8, 1920])\n",
      "base_model.model.backbone.h.23.attn.c_attn.lora_B.default.weight: torch.Size([5760, 8])\n",
      "base_model.model.backbone.h.23.attn.c_proj.lora_A.default.weight: torch.Size([8, 1920])\n",
      "base_model.model.backbone.h.23.attn.c_proj.lora_B.default.weight: torch.Size([1920, 8])\n",
      "base_model.model.backbone.h.23.mlp.c_proj.lora_A.default.weight: torch.Size([8, 7680])\n",
      "base_model.model.backbone.h.23.mlp.c_proj.lora_B.default.weight: torch.Size([1920, 8])\n",
      "base_model.model.v_head.weight: torch.Size([1, 1920])\n",
      "base_model.model.v_head.bias: torch.Size([1])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "training_args = RewardConfig(\n",
    "    output_dir=\"/content/drive/MyDrive/rm\",\n",
    "    overwrite_output_dir=True,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    gradient_accumulation_steps=16,\n",
    "\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.05,\n",
    "\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=5e-4,\n",
    "\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_accuracy\",\n",
    "    greater_is_better=True,\n",
    "\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    save_total_limit=2,\n",
    "\n",
    "    bf16=True,\n",
    "    report_to=\"tensorboard\",\n",
    "\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    "\n",
    "    seed = 42,\n",
    "    max_length = 1024,\n",
    "    weight_decay = 0.01\n",
    ")"
   ],
   "metadata": {},
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "if not hasattr(rm_model, \"warnings_issued\"):\n",
    "  rm_model.warnings_issued = {}"
   ],
   "metadata": {},
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class MyRewardTrainer(RewardTrainer):\n",
    "  def compute_loss(\n",
    "    self,\n",
    "    model,\n",
    "    inputs,\n",
    "    return_outputs=False,\n",
    "    num_items_in_batch=None\n",
    "):\n",
    "    print(\"[DEBUG] type(inputs):\", type(inputs))\n",
    "    print(\"[DEBUG] keys:\", inputs.keys() if isinstance(inputs, dict) else \"Not a dict\")\n",
    "    print(\"[DEBUG] input_ids_chosen shape:\", inputs[\"input_ids_chosen\"].shape if isinstance(inputs, dict) else \"???\")\n",
    "\n",
    "    return super().compute_loss(model, inputs, return_outputs, num_items_in_batch)"
   ],
   "metadata": {},
   "execution_count": 66,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class CustomRewardTrainer(RewardTrainer):\n",
    "  def __init__(self, tokenizer=None, *args, **kwargs):\n",
    "    super().__init__(*args, **kwargs)\n",
    "    self.tokenizer = tokenizer\n",
    "\n",
    "  def compute_loss(self, model, inputs, num_items_in_batch=None, return_outputs=False):\n",
    "    \"\"\"\n",
    "    Compute pairwise loss: reward_chosen > reward_rejected.\n",
    "    Loss = -log(sigmoid(reward_chosen - reward_rejected))\n",
    "    \"\"\"\n",
    "    rewards_chosen = model(\n",
    "        input_ids=inputs[\"input_ids_chosen\"],\n",
    "        attention_mask=inputs[\"attention_mask_chosen\"]\n",
    "    )\n",
    "\n",
    "    rewards_rejected = model(\n",
    "        input_ids=inputs[\"input_ids_rejected\"],\n",
    "        attention_mask=inputs[\"attention_mask_rejected\"]\n",
    "    )\n",
    "\n",
    "    if rewards_chosen.ndim == 2:\n",
    "      rewards_chosen = rewards_chosen[:, -1]\n",
    "      rewards_rejected = rewards_rejected[:, -1]\n",
    "    elif rewards_chosen.ndim == 1:\n",
    "      pass\n",
    "    else:\n",
    "      raise ValueError(f\"Unexpected reward shape: {rewards_chosen.shape}\")\n",
    "\n",
    "    loss = -torch.nn.functional.logsigmoid(rewards_chosen - rewards_rejected).mean()\n",
    "\n",
    "    if return_outputs:\n",
    "      return loss, {\"chosen_reward\": rewards_chosen, \"rejected_reward\": rewards_rejected}\n",
    "    return loss\n",
    "\n",
    "  def prediction_step(self, model, inputs, prediction_loss_only, ignore_keys=None):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      reward_chosen = model(\n",
    "          input_ids=inputs[\"input_ids_chosen\"],\n",
    "          attention_mask=inputs[\"attention_mask_chosen\"]\n",
    "      )\n",
    "\n",
    "      reward_rejected = model(\n",
    "          input_ids=inputs[\"input_ids_rejected\"],\n",
    "          attention_mask=inputs[\"attention_mask_rejected\"]\n",
    "      )\n",
    "\n",
    "      reward_chosen = reward_chosen.view(-1)\n",
    "      reward_rejected = reward_rejected.view(-1)\n",
    "\n",
    "      rewards = torch.stack([reward_chosen, reward_rejected])  # [2, B]\n",
    "      probs = rewards.softmax(dim=0).T  # [B, 2]\n",
    "\n",
    "      labels = torch.zeros(probs.shape[0], dtype=torch.long, device=probs.device)\n",
    "\n",
    "      if prediction_loss_only:\n",
    "        return (None, None, None)\n",
    "    return (None, probs, labels)"
   ],
   "metadata": {},
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def compute_metrics(eval_preds):\n",
    "  logits, labels = eval_preds\n",
    "  preds = logits.argmax(axis=1)\n",
    "  acc = (preds == labels).mean().item()\n",
    "  return {\"accuracy\": acc}"
   ],
   "metadata": {},
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "trainer = CustomRewardTrainer(\n",
    "    model=rm_model,\n",
    "    args=training_args,\n",
    "    train_dataset=rm_train_dataset4,\n",
    "    eval_dataset=rm_val_dataset4,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    #peft_config=lora_config,\n",
    ")"
   ],
   "metadata": {},
   "execution_count": 18,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "Trainer.tokenizer is now deprecated. You should use `Trainer.processing_class = processing_class` instead.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "trainer.train()"
   ],
   "metadata": {},
   "execution_count": 19,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='630' max='630' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [630/630 36:57, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>5.264100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.914152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.009000</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.927565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.505600</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.931590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.460200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.937626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.580700</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.934943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.321700</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.934272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mchosen_text                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mrejected_text                                \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mlogits          \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
       "│ ### Instruction(명령어):                     │ ### Instruction(명령어):                      │ [0.9734, 0.0266] │\n",
       "│ 다음 문장에 다섯 개의 동작 동사를            │ 다음 문장에 다섯 개의 동작 동사를 추가합니다. │                  │\n",
       "│ 추가합니다.                                  │ 잭                                            │                  │\n",
       "│ 잭                                           │                                               │                  │\n",
       "│                                              │ ### Response(응답)::\"잭은 노래하고 있습니다\"… │                  │\n",
       "│ ### Response(응답):Jack went running, Jack   │ \"제이미는 팝콘을 먹습니다\", \"잭은 춤을 추고   │                  │\n",
       "│ said hello, Jack jumped up and down, Jack    │ 있습니다\".</s>                                │                  │\n",
       "│ cried loudly, Jack danced happily</s>        │                                               │                  │\n",
       "├──────────────────────────────────────────────┼───────────────────────────────────────────────┼──────────────────┤\n",
       "│ ### Instruction(명령어):                     │ ### Instruction(명령어):                      │ [0.9909, 0.0091] │\n",
       "│ 다음 문장에 다섯 개의 동작 동사를            │ 다음 문장에 다섯 개의 동작 동사를 추가합니다. │                  │\n",
       "│ 추가합니다.                                  │ 잭                                            │                  │\n",
       "│ 잭                                           │                                               │                  │\n",
       "│                                              │ ### Response(응답):: 잭이 노래하는 것을       │                  │\n",
       "│ ### Response(응답):Jack went running, Jack   │ 들었습니다.</s>                               │                  │\n",
       "│ said hello, Jack jumped up and down, Jack    │                                               │                  │\n",
       "│ cried loudly, Jack danced happily</s>        │                                               │                  │\n",
       "├──────────────────────────────────────────────┼───────────────────────────────────────────────┼──────────────────┤\n",
       "│ ### Instruction(명령어):                     │ ### Instruction(명령어):                      │ [0.7491, 0.2509] │\n",
       "│ 다음 문장에 다섯 개의 동작 동사를            │ 다음 문장에 다섯 개의 동작 동사를 추가합니다. │                  │\n",
       "│ 추가합니다.                                  │ 잭                                            │                  │\n",
       "│ 잭                                           │                                               │                  │\n",
       "│                                              │ ### Response(응답):: 잭이 노래하는 것을       │                  │\n",
       "│ ### Response(응답)::\"잭은 노래하고           │ 들었습니다.</s>                               │                  │\n",
       "│ 있습니다\", \"제이미는 팝콘을 먹습니다\", \"잭 … │                                               │                  │\n",
       "│ 춤을 추고 있습니다\".</s>                     │                                               │                  │\n",
       "├──────────────────────────────────────────────┼───────────────────────────────────────────────┼──────────────────┤\n",
       "│ ### Instruction(명령어):                     │ ### Instruction(명령어):                      │ [0.9757, 0.0243] │\n",
       "│ 일반적으로 토마토를 베이스로 한 소스와 함께  │ 일반적으로 토마토를 베이스로 한 소스와 함께   │                  │\n",
       "│ 제공되는 파스타의 한 종류를 말하세요.        │ 제공되는 파스타의 한 종류를 말하세요.         │                  │\n",
       "│                                              │                                               │                  │\n",
       "│ ### Response(응답):\"스파게티\"</s>            │ ### Response(응답):토마토 소스                │                  │\n",
       "│                                              │ 파스타입니다.</s>                             │                  │\n",
       "└──────────────────────────────────────────────┴───────────────────────────────────────────────┴──────────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> chosen_text                                  </span>┃<span style=\"font-weight: bold\"> rejected_text                                 </span>┃<span style=\"font-weight: bold\"> logits           </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
       "│ ### Instruction(명령어):                     │ ### Instruction(명령어):                      │ [0.9734, 0.0266] │\n",
       "│ 다음 문장에 다섯 개의 동작 동사를            │ 다음 문장에 다섯 개의 동작 동사를 추가합니다. │                  │\n",
       "│ 추가합니다.                                  │ 잭                                            │                  │\n",
       "│ 잭                                           │                                               │                  │\n",
       "│                                              │ ### Response(응답)::\"잭은 노래하고 있습니다\"… │                  │\n",
       "│ ### Response(응답):Jack went running, Jack   │ \"제이미는 팝콘을 먹습니다\", \"잭은 춤을 추고   │                  │\n",
       "│ said hello, Jack jumped up and down, Jack    │ 있습니다\".&lt;/s&gt;                                │                  │\n",
       "│ cried loudly, Jack danced happily&lt;/s&gt;        │                                               │                  │\n",
       "├──────────────────────────────────────────────┼───────────────────────────────────────────────┼──────────────────┤\n",
       "│ ### Instruction(명령어):                     │ ### Instruction(명령어):                      │ [0.9909, 0.0091] │\n",
       "│ 다음 문장에 다섯 개의 동작 동사를            │ 다음 문장에 다섯 개의 동작 동사를 추가합니다. │                  │\n",
       "│ 추가합니다.                                  │ 잭                                            │                  │\n",
       "│ 잭                                           │                                               │                  │\n",
       "│                                              │ ### Response(응답):: 잭이 노래하는 것을       │                  │\n",
       "│ ### Response(응답):Jack went running, Jack   │ 들었습니다.&lt;/s&gt;                               │                  │\n",
       "│ said hello, Jack jumped up and down, Jack    │                                               │                  │\n",
       "│ cried loudly, Jack danced happily&lt;/s&gt;        │                                               │                  │\n",
       "├──────────────────────────────────────────────┼───────────────────────────────────────────────┼──────────────────┤\n",
       "│ ### Instruction(명령어):                     │ ### Instruction(명령어):                      │ [0.7491, 0.2509] │\n",
       "│ 다음 문장에 다섯 개의 동작 동사를            │ 다음 문장에 다섯 개의 동작 동사를 추가합니다. │                  │\n",
       "│ 추가합니다.                                  │ 잭                                            │                  │\n",
       "│ 잭                                           │                                               │                  │\n",
       "│                                              │ ### Response(응답):: 잭이 노래하는 것을       │                  │\n",
       "│ ### Response(응답)::\"잭은 노래하고           │ 들었습니다.&lt;/s&gt;                               │                  │\n",
       "│ 있습니다\", \"제이미는 팝콘을 먹습니다\", \"잭 … │                                               │                  │\n",
       "│ 춤을 추고 있습니다\".&lt;/s&gt;                     │                                               │                  │\n",
       "├──────────────────────────────────────────────┼───────────────────────────────────────────────┼──────────────────┤\n",
       "│ ### Instruction(명령어):                     │ ### Instruction(명령어):                      │ [0.9757, 0.0243] │\n",
       "│ 일반적으로 토마토를 베이스로 한 소스와 함께  │ 일반적으로 토마토를 베이스로 한 소스와 함께   │                  │\n",
       "│ 제공되는 파스타의 한 종류를 말하세요.        │ 제공되는 파스타의 한 종류를 말하세요.         │                  │\n",
       "│                                              │                                               │                  │\n",
       "│ ### Response(응답):\"스파게티\"&lt;/s&gt;            │ ### Response(응답):토마토 소스                │                  │\n",
       "│                                              │ 파스타입니다.&lt;/s&gt;                             │                  │\n",
       "└──────────────────────────────────────────────┴───────────────────────────────────────────────┴──────────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mchosen_text                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mrejected_text                                \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mlogits          \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
       "│ ### Instruction(명령어):                     │ ### Instruction(명령어):                      │ [0.9994, 0.0006] │\n",
       "│ 다음 문장에 다섯 개의 동작 동사를            │ 다음 문장에 다섯 개의 동작 동사를 추가합니다. │                  │\n",
       "│ 추가합니다.                                  │ 잭                                            │                  │\n",
       "│ 잭                                           │                                               │                  │\n",
       "│                                              │ ### Response(응답)::\"잭은 노래하고 있습니다\"… │                  │\n",
       "│ ### Response(응답):Jack went running, Jack   │ \"제이미는 팝콘을 먹습니다\", \"잭은 춤을 추고   │                  │\n",
       "│ said hello, Jack jumped up and down, Jack    │ 있습니다\".</s>                                │                  │\n",
       "│ cried loudly, Jack danced happily</s>        │                                               │                  │\n",
       "├──────────────────────────────────────────────┼───────────────────────────────────────────────┼──────────────────┤\n",
       "│ ### Instruction(명령어):                     │ ### Instruction(명령어):                      │ [0.9999, 0.0001] │\n",
       "│ 다음 문장에 다섯 개의 동작 동사를            │ 다음 문장에 다섯 개의 동작 동사를 추가합니다. │                  │\n",
       "│ 추가합니다.                                  │ 잭                                            │                  │\n",
       "│ 잭                                           │                                               │                  │\n",
       "│                                              │ ### Response(응답):: 잭이 노래하는 것을       │                  │\n",
       "│ ### Response(응답):Jack went running, Jack   │ 들었습니다.</s>                               │                  │\n",
       "│ said hello, Jack jumped up and down, Jack    │                                               │                  │\n",
       "│ cried loudly, Jack danced happily</s>        │                                               │                  │\n",
       "├──────────────────────────────────────────────┼───────────────────────────────────────────────┼──────────────────┤\n",
       "│ ### Instruction(명령어):                     │ ### Instruction(명령어):                      │ [0.9205, 0.0795] │\n",
       "│ 다음 문장에 다섯 개의 동작 동사를            │ 다음 문장에 다섯 개의 동작 동사를 추가합니다. │                  │\n",
       "│ 추가합니다.                                  │ 잭                                            │                  │\n",
       "│ 잭                                           │                                               │                  │\n",
       "│                                              │ ### Response(응답):: 잭이 노래하는 것을       │                  │\n",
       "│ ### Response(응답)::\"잭은 노래하고           │ 들었습니다.</s>                               │                  │\n",
       "│ 있습니다\", \"제이미는 팝콘을 먹습니다\", \"잭 … │                                               │                  │\n",
       "│ 춤을 추고 있습니다\".</s>                     │                                               │                  │\n",
       "├──────────────────────────────────────────────┼───────────────────────────────────────────────┼──────────────────┤\n",
       "│ ### Instruction(명령어):                     │ ### Instruction(명령어):                      │ [0.9546, 0.0454] │\n",
       "│ 일반적으로 토마토를 베이스로 한 소스와 함께  │ 일반적으로 토마토를 베이스로 한 소스와 함께   │                  │\n",
       "│ 제공되는 파스타의 한 종류를 말하세요.        │ 제공되는 파스타의 한 종류를 말하세요.         │                  │\n",
       "│                                              │                                               │                  │\n",
       "│ ### Response(응답):\"스파게티\"</s>            │ ### Response(응답):토마토 소스                │                  │\n",
       "│                                              │ 파스타입니다.</s>                             │                  │\n",
       "└──────────────────────────────────────────────┴───────────────────────────────────────────────┴──────────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> chosen_text                                  </span>┃<span style=\"font-weight: bold\"> rejected_text                                 </span>┃<span style=\"font-weight: bold\"> logits           </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
       "│ ### Instruction(명령어):                     │ ### Instruction(명령어):                      │ [0.9994, 0.0006] │\n",
       "│ 다음 문장에 다섯 개의 동작 동사를            │ 다음 문장에 다섯 개의 동작 동사를 추가합니다. │                  │\n",
       "│ 추가합니다.                                  │ 잭                                            │                  │\n",
       "│ 잭                                           │                                               │                  │\n",
       "│                                              │ ### Response(응답)::\"잭은 노래하고 있습니다\"… │                  │\n",
       "│ ### Response(응답):Jack went running, Jack   │ \"제이미는 팝콘을 먹습니다\", \"잭은 춤을 추고   │                  │\n",
       "│ said hello, Jack jumped up and down, Jack    │ 있습니다\".&lt;/s&gt;                                │                  │\n",
       "│ cried loudly, Jack danced happily&lt;/s&gt;        │                                               │                  │\n",
       "├──────────────────────────────────────────────┼───────────────────────────────────────────────┼──────────────────┤\n",
       "│ ### Instruction(명령어):                     │ ### Instruction(명령어):                      │ [0.9999, 0.0001] │\n",
       "│ 다음 문장에 다섯 개의 동작 동사를            │ 다음 문장에 다섯 개의 동작 동사를 추가합니다. │                  │\n",
       "│ 추가합니다.                                  │ 잭                                            │                  │\n",
       "│ 잭                                           │                                               │                  │\n",
       "│                                              │ ### Response(응답):: 잭이 노래하는 것을       │                  │\n",
       "│ ### Response(응답):Jack went running, Jack   │ 들었습니다.&lt;/s&gt;                               │                  │\n",
       "│ said hello, Jack jumped up and down, Jack    │                                               │                  │\n",
       "│ cried loudly, Jack danced happily&lt;/s&gt;        │                                               │                  │\n",
       "├──────────────────────────────────────────────┼───────────────────────────────────────────────┼──────────────────┤\n",
       "│ ### Instruction(명령어):                     │ ### Instruction(명령어):                      │ [0.9205, 0.0795] │\n",
       "│ 다음 문장에 다섯 개의 동작 동사를            │ 다음 문장에 다섯 개의 동작 동사를 추가합니다. │                  │\n",
       "│ 추가합니다.                                  │ 잭                                            │                  │\n",
       "│ 잭                                           │                                               │                  │\n",
       "│                                              │ ### Response(응답):: 잭이 노래하는 것을       │                  │\n",
       "│ ### Response(응답)::\"잭은 노래하고           │ 들었습니다.&lt;/s&gt;                               │                  │\n",
       "│ 있습니다\", \"제이미는 팝콘을 먹습니다\", \"잭 … │                                               │                  │\n",
       "│ 춤을 추고 있습니다\".&lt;/s&gt;                     │                                               │                  │\n",
       "├──────────────────────────────────────────────┼───────────────────────────────────────────────┼──────────────────┤\n",
       "│ ### Instruction(명령어):                     │ ### Instruction(명령어):                      │ [0.9546, 0.0454] │\n",
       "│ 일반적으로 토마토를 베이스로 한 소스와 함께  │ 일반적으로 토마토를 베이스로 한 소스와 함께   │                  │\n",
       "│ 제공되는 파스타의 한 종류를 말하세요.        │ 제공되는 파스타의 한 종류를 말하세요.         │                  │\n",
       "│                                              │                                               │                  │\n",
       "│ ### Response(응답):\"스파게티\"&lt;/s&gt;            │ ### Response(응답):토마토 소스                │                  │\n",
       "│                                              │ 파스타입니다.&lt;/s&gt;                             │                  │\n",
       "└──────────────────────────────────────────────┴───────────────────────────────────────────────┴──────────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mchosen_text                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mrejected_text                                \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mlogits          \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
       "│ ### Instruction(명령어):                     │ ### Instruction(명령어):                      │ [0.997, 0.003]   │\n",
       "│ 다음 문장에 다섯 개의 동작 동사를            │ 다음 문장에 다섯 개의 동작 동사를 추가합니다. │                  │\n",
       "│ 추가합니다.                                  │ 잭                                            │                  │\n",
       "│ 잭                                           │                                               │                  │\n",
       "│                                              │ ### Response(응답)::\"잭은 노래하고 있습니다\"… │                  │\n",
       "│ ### Response(응답):Jack went running, Jack   │ \"제이미는 팝콘을 먹습니다\", \"잭은 춤을 추고   │                  │\n",
       "│ said hello, Jack jumped up and down, Jack    │ 있습니다\".</s>                                │                  │\n",
       "│ cried loudly, Jack danced happily</s>        │                                               │                  │\n",
       "├──────────────────────────────────────────────┼───────────────────────────────────────────────┼──────────────────┤\n",
       "│ ### Instruction(명령어):                     │ ### Instruction(명령어):                      │ [0.9994, 0.0006] │\n",
       "│ 다음 문장에 다섯 개의 동작 동사를            │ 다음 문장에 다섯 개의 동작 동사를 추가합니다. │                  │\n",
       "│ 추가합니다.                                  │ 잭                                            │                  │\n",
       "│ 잭                                           │                                               │                  │\n",
       "│                                              │ ### Response(응답):: 잭이 노래하는 것을       │                  │\n",
       "│ ### Response(응답):Jack went running, Jack   │ 들었습니다.</s>                               │                  │\n",
       "│ said hello, Jack jumped up and down, Jack    │                                               │                  │\n",
       "│ cried loudly, Jack danced happily</s>        │                                               │                  │\n",
       "├──────────────────────────────────────────────┼───────────────────────────────────────────────┼──────────────────┤\n",
       "│ ### Instruction(명령어):                     │ ### Instruction(명령어):                      │ [0.8439, 0.1561] │\n",
       "│ 다음 문장에 다섯 개의 동작 동사를            │ 다음 문장에 다섯 개의 동작 동사를 추가합니다. │                  │\n",
       "│ 추가합니다.                                  │ 잭                                            │                  │\n",
       "│ 잭                                           │                                               │                  │\n",
       "│                                              │ ### Response(응답):: 잭이 노래하는 것을       │                  │\n",
       "│ ### Response(응답)::\"잭은 노래하고           │ 들었습니다.</s>                               │                  │\n",
       "│ 있습니다\", \"제이미는 팝콘을 먹습니다\", \"잭 … │                                               │                  │\n",
       "│ 춤을 추고 있습니다\".</s>                     │                                               │                  │\n",
       "├──────────────────────────────────────────────┼───────────────────────────────────────────────┼──────────────────┤\n",
       "│ ### Instruction(명령어):                     │ ### Instruction(명령어):                      │ [0.9959, 0.0041] │\n",
       "│ 일반적으로 토마토를 베이스로 한 소스와 함께  │ 일반적으로 토마토를 베이스로 한 소스와 함께   │                  │\n",
       "│ 제공되는 파스타의 한 종류를 말하세요.        │ 제공되는 파스타의 한 종류를 말하세요.         │                  │\n",
       "│                                              │                                               │                  │\n",
       "│ ### Response(응답):\"스파게티\"</s>            │ ### Response(응답):토마토 소스                │                  │\n",
       "│                                              │ 파스타입니다.</s>                             │                  │\n",
       "└──────────────────────────────────────────────┴───────────────────────────────────────────────┴──────────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> chosen_text                                  </span>┃<span style=\"font-weight: bold\"> rejected_text                                 </span>┃<span style=\"font-weight: bold\"> logits           </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
       "│ ### Instruction(명령어):                     │ ### Instruction(명령어):                      │ [0.997, 0.003]   │\n",
       "│ 다음 문장에 다섯 개의 동작 동사를            │ 다음 문장에 다섯 개의 동작 동사를 추가합니다. │                  │\n",
       "│ 추가합니다.                                  │ 잭                                            │                  │\n",
       "│ 잭                                           │                                               │                  │\n",
       "│                                              │ ### Response(응답)::\"잭은 노래하고 있습니다\"… │                  │\n",
       "│ ### Response(응답):Jack went running, Jack   │ \"제이미는 팝콘을 먹습니다\", \"잭은 춤을 추고   │                  │\n",
       "│ said hello, Jack jumped up and down, Jack    │ 있습니다\".&lt;/s&gt;                                │                  │\n",
       "│ cried loudly, Jack danced happily&lt;/s&gt;        │                                               │                  │\n",
       "├──────────────────────────────────────────────┼───────────────────────────────────────────────┼──────────────────┤\n",
       "│ ### Instruction(명령어):                     │ ### Instruction(명령어):                      │ [0.9994, 0.0006] │\n",
       "│ 다음 문장에 다섯 개의 동작 동사를            │ 다음 문장에 다섯 개의 동작 동사를 추가합니다. │                  │\n",
       "│ 추가합니다.                                  │ 잭                                            │                  │\n",
       "│ 잭                                           │                                               │                  │\n",
       "│                                              │ ### Response(응답):: 잭이 노래하는 것을       │                  │\n",
       "│ ### Response(응답):Jack went running, Jack   │ 들었습니다.&lt;/s&gt;                               │                  │\n",
       "│ said hello, Jack jumped up and down, Jack    │                                               │                  │\n",
       "│ cried loudly, Jack danced happily&lt;/s&gt;        │                                               │                  │\n",
       "├──────────────────────────────────────────────┼───────────────────────────────────────────────┼──────────────────┤\n",
       "│ ### Instruction(명령어):                     │ ### Instruction(명령어):                      │ [0.8439, 0.1561] │\n",
       "│ 다음 문장에 다섯 개의 동작 동사를            │ 다음 문장에 다섯 개의 동작 동사를 추가합니다. │                  │\n",
       "│ 추가합니다.                                  │ 잭                                            │                  │\n",
       "│ 잭                                           │                                               │                  │\n",
       "│                                              │ ### Response(응답):: 잭이 노래하는 것을       │                  │\n",
       "│ ### Response(응답)::\"잭은 노래하고           │ 들었습니다.&lt;/s&gt;                               │                  │\n",
       "│ 있습니다\", \"제이미는 팝콘을 먹습니다\", \"잭 … │                                               │                  │\n",
       "│ 춤을 추고 있습니다\".&lt;/s&gt;                     │                                               │                  │\n",
       "├──────────────────────────────────────────────┼───────────────────────────────────────────────┼──────────────────┤\n",
       "│ ### Instruction(명령어):                     │ ### Instruction(명령어):                      │ [0.9959, 0.0041] │\n",
       "│ 일반적으로 토마토를 베이스로 한 소스와 함께  │ 일반적으로 토마토를 베이스로 한 소스와 함께   │                  │\n",
       "│ 제공되는 파스타의 한 종류를 말하세요.        │ 제공되는 파스타의 한 종류를 말하세요.         │                  │\n",
       "│                                              │                                               │                  │\n",
       "│ ### Response(응답):\"스파게티\"&lt;/s&gt;            │ ### Response(응답):토마토 소스                │                  │\n",
       "│                                              │ 파스타입니다.&lt;/s&gt;                             │                  │\n",
       "└──────────────────────────────────────────────┴───────────────────────────────────────────────┴──────────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mchosen_text                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mrejected_text                                \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mlogits          \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
       "│ ### Instruction(명령어):                     │ ### Instruction(명령어):                      │ [0.9996, 0.0004] │\n",
       "│ 다음 문장에 다섯 개의 동작 동사를            │ 다음 문장에 다섯 개의 동작 동사를 추가합니다. │                  │\n",
       "│ 추가합니다.                                  │ 잭                                            │                  │\n",
       "│ 잭                                           │                                               │                  │\n",
       "│                                              │ ### Response(응답)::\"잭은 노래하고 있습니다\"… │                  │\n",
       "│ ### Response(응답):Jack went running, Jack   │ \"제이미는 팝콘을 먹습니다\", \"잭은 춤을 추고   │                  │\n",
       "│ said hello, Jack jumped up and down, Jack    │ 있습니다\".</s>                                │                  │\n",
       "│ cried loudly, Jack danced happily</s>        │                                               │                  │\n",
       "├──────────────────────────────────────────────┼───────────────────────────────────────────────┼──────────────────┤\n",
       "│ ### Instruction(명령어):                     │ ### Instruction(명령어):                      │ [1.0, 0.0]       │\n",
       "│ 다음 문장에 다섯 개의 동작 동사를            │ 다음 문장에 다섯 개의 동작 동사를 추가합니다. │                  │\n",
       "│ 추가합니다.                                  │ 잭                                            │                  │\n",
       "│ 잭                                           │                                               │                  │\n",
       "│                                              │ ### Response(응답):: 잭이 노래하는 것을       │                  │\n",
       "│ ### Response(응답):Jack went running, Jack   │ 들었습니다.</s>                               │                  │\n",
       "│ said hello, Jack jumped up and down, Jack    │                                               │                  │\n",
       "│ cried loudly, Jack danced happily</s>        │                                               │                  │\n",
       "├──────────────────────────────────────────────┼───────────────────────────────────────────────┼──────────────────┤\n",
       "│ ### Instruction(명령어):                     │ ### Instruction(명령어):                      │ [0.9826, 0.0174] │\n",
       "│ 다음 문장에 다섯 개의 동작 동사를            │ 다음 문장에 다섯 개의 동작 동사를 추가합니다. │                  │\n",
       "│ 추가합니다.                                  │ 잭                                            │                  │\n",
       "│ 잭                                           │                                               │                  │\n",
       "│                                              │ ### Response(응답):: 잭이 노래하는 것을       │                  │\n",
       "│ ### Response(응답)::\"잭은 노래하고           │ 들었습니다.</s>                               │                  │\n",
       "│ 있습니다\", \"제이미는 팝콘을 먹습니다\", \"잭 … │                                               │                  │\n",
       "│ 춤을 추고 있습니다\".</s>                     │                                               │                  │\n",
       "├──────────────────────────────────────────────┼───────────────────────────────────────────────┼──────────────────┤\n",
       "│ ### Instruction(명령어):                     │ ### Instruction(명령어):                      │ [0.9995, 0.0005] │\n",
       "│ 일반적으로 토마토를 베이스로 한 소스와 함께  │ 일반적으로 토마토를 베이스로 한 소스와 함께   │                  │\n",
       "│ 제공되는 파스타의 한 종류를 말하세요.        │ 제공되는 파스타의 한 종류를 말하세요.         │                  │\n",
       "│                                              │                                               │                  │\n",
       "│ ### Response(응답):\"스파게티\"</s>            │ ### Response(응답):토마토 소스                │                  │\n",
       "│                                              │ 파스타입니다.</s>                             │                  │\n",
       "└──────────────────────────────────────────────┴───────────────────────────────────────────────┴──────────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> chosen_text                                  </span>┃<span style=\"font-weight: bold\"> rejected_text                                 </span>┃<span style=\"font-weight: bold\"> logits           </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━┩\n",
       "│ ### Instruction(명령어):                     │ ### Instruction(명령어):                      │ [0.9996, 0.0004] │\n",
       "│ 다음 문장에 다섯 개의 동작 동사를            │ 다음 문장에 다섯 개의 동작 동사를 추가합니다. │                  │\n",
       "│ 추가합니다.                                  │ 잭                                            │                  │\n",
       "│ 잭                                           │                                               │                  │\n",
       "│                                              │ ### Response(응답)::\"잭은 노래하고 있습니다\"… │                  │\n",
       "│ ### Response(응답):Jack went running, Jack   │ \"제이미는 팝콘을 먹습니다\", \"잭은 춤을 추고   │                  │\n",
       "│ said hello, Jack jumped up and down, Jack    │ 있습니다\".&lt;/s&gt;                                │                  │\n",
       "│ cried loudly, Jack danced happily&lt;/s&gt;        │                                               │                  │\n",
       "├──────────────────────────────────────────────┼───────────────────────────────────────────────┼──────────────────┤\n",
       "│ ### Instruction(명령어):                     │ ### Instruction(명령어):                      │ [1.0, 0.0]       │\n",
       "│ 다음 문장에 다섯 개의 동작 동사를            │ 다음 문장에 다섯 개의 동작 동사를 추가합니다. │                  │\n",
       "│ 추가합니다.                                  │ 잭                                            │                  │\n",
       "│ 잭                                           │                                               │                  │\n",
       "│                                              │ ### Response(응답):: 잭이 노래하는 것을       │                  │\n",
       "│ ### Response(응답):Jack went running, Jack   │ 들었습니다.&lt;/s&gt;                               │                  │\n",
       "│ said hello, Jack jumped up and down, Jack    │                                               │                  │\n",
       "│ cried loudly, Jack danced happily&lt;/s&gt;        │                                               │                  │\n",
       "├──────────────────────────────────────────────┼───────────────────────────────────────────────┼──────────────────┤\n",
       "│ ### Instruction(명령어):                     │ ### Instruction(명령어):                      │ [0.9826, 0.0174] │\n",
       "│ 다음 문장에 다섯 개의 동작 동사를            │ 다음 문장에 다섯 개의 동작 동사를 추가합니다. │                  │\n",
       "│ 추가합니다.                                  │ 잭                                            │                  │\n",
       "│ 잭                                           │                                               │                  │\n",
       "│                                              │ ### Response(응답):: 잭이 노래하는 것을       │                  │\n",
       "│ ### Response(응답)::\"잭은 노래하고           │ 들었습니다.&lt;/s&gt;                               │                  │\n",
       "│ 있습니다\", \"제이미는 팝콘을 먹습니다\", \"잭 … │                                               │                  │\n",
       "│ 춤을 추고 있습니다\".&lt;/s&gt;                     │                                               │                  │\n",
       "├──────────────────────────────────────────────┼───────────────────────────────────────────────┼──────────────────┤\n",
       "│ ### Instruction(명령어):                     │ ### Instruction(명령어):                      │ [0.9995, 0.0005] │\n",
       "│ 일반적으로 토마토를 베이스로 한 소스와 함께  │ 일반적으로 토마토를 베이스로 한 소스와 함께   │                  │\n",
       "│ 제공되는 파스타의 한 종류를 말하세요.        │ 제공되는 파스타의 한 종류를 말하세요.         │                  │\n",
       "│                                              │                                               │                  │\n",
       "│ ### Response(응답):\"스파게티\"&lt;/s&gt;            │ ### Response(응답):토마토 소스                │                  │\n",
       "│                                              │ 파스타입니다.&lt;/s&gt;                             │                  │\n",
       "└──────────────────────────────────────────────┴───────────────────────────────────────────────┴──────────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mchosen_text                                     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mrejected_text                                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mlogits    \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│ ### Instruction(명령어):                         │ ### Instruction(명령어):                        │ [1.0, 0.0] │\n",
       "│ 다음 문장에 다섯 개의 동작 동사를 추가합니다.    │ 다음 문장에 다섯 개의 동작 동사를 추가합니다.   │            │\n",
       "│ 잭                                               │ 잭                                              │            │\n",
       "│                                                  │                                                 │            │\n",
       "│ ### Response(응답):Jack went running, Jack said  │ ### Response(응답)::\"잭은 노래하고 있습니다\",   │            │\n",
       "│ hello, Jack jumped up and down, Jack cried       │ \"제이미는 팝콘을 먹습니다\", \"잭은 춤을 추고     │            │\n",
       "│ loudly, Jack danced happily</s>                  │ 있습니다\".</s>                                  │            │\n",
       "├──────────────────────────────────────────────────┼─────────────────────────────────────────────────┼────────────┤\n",
       "│ ### Instruction(명령어):                         │ ### Instruction(명령어):                        │ [1.0, 0.0] │\n",
       "│ 다음 문장에 다섯 개의 동작 동사를 추가합니다.    │ 다음 문장에 다섯 개의 동작 동사를 추가합니다.   │            │\n",
       "│ 잭                                               │ 잭                                              │            │\n",
       "│                                                  │                                                 │            │\n",
       "│ ### Response(응답):Jack went running, Jack said  │ ### Response(응답):: 잭이 노래하는 것을         │            │\n",
       "│ hello, Jack jumped up and down, Jack cried       │ 들었습니다.</s>                                 │            │\n",
       "│ loudly, Jack danced happily</s>                  │                                                 │            │\n",
       "├──────────────────────────────────────────────────┼─────────────────────────────────────────────────┼────────────┤\n",
       "│ ### Instruction(명령어):                         │ ### Instruction(명령어):                        │ [1.0, 0.0] │\n",
       "│ 다음 문장에 다섯 개의 동작 동사를 추가합니다.    │ 다음 문장에 다섯 개의 동작 동사를 추가합니다.   │            │\n",
       "│ 잭                                               │ 잭                                              │            │\n",
       "│                                                  │                                                 │            │\n",
       "│ ### Response(응답)::\"잭은 노래하고 있습니다\",    │ ### Response(응답):: 잭이 노래하는 것을         │            │\n",
       "│ \"제이미는 팝콘을 먹습니다\", \"잭은 춤을 추고      │ 들었습니다.</s>                                 │            │\n",
       "│ 있습니다\".</s>                                   │                                                 │            │\n",
       "├──────────────────────────────────────────────────┼─────────────────────────────────────────────────┼────────────┤\n",
       "│ ### Instruction(명령어):                         │ ### Instruction(명령어):                        │ [1.0, 0.0] │\n",
       "│ 일반적으로 토마토를 베이스로 한 소스와 함께      │ 일반적으로 토마토를 베이스로 한 소스와 함께     │            │\n",
       "│ 제공되는 파스타의 한 종류를 말하세요.            │ 제공되는 파스타의 한 종류를 말하세요.           │            │\n",
       "│                                                  │                                                 │            │\n",
       "│ ### Response(응답):\"스파게티\"</s>                │ ### Response(응답):토마토 소스                  │            │\n",
       "│                                                  │ 파스타입니다.</s>                               │            │\n",
       "└──────────────────────────────────────────────────┴─────────────────────────────────────────────────┴────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> chosen_text                                      </span>┃<span style=\"font-weight: bold\"> rejected_text                                   </span>┃<span style=\"font-weight: bold\"> logits     </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│ ### Instruction(명령어):                         │ ### Instruction(명령어):                        │ [1.0, 0.0] │\n",
       "│ 다음 문장에 다섯 개의 동작 동사를 추가합니다.    │ 다음 문장에 다섯 개의 동작 동사를 추가합니다.   │            │\n",
       "│ 잭                                               │ 잭                                              │            │\n",
       "│                                                  │                                                 │            │\n",
       "│ ### Response(응답):Jack went running, Jack said  │ ### Response(응답)::\"잭은 노래하고 있습니다\",   │            │\n",
       "│ hello, Jack jumped up and down, Jack cried       │ \"제이미는 팝콘을 먹습니다\", \"잭은 춤을 추고     │            │\n",
       "│ loudly, Jack danced happily&lt;/s&gt;                  │ 있습니다\".&lt;/s&gt;                                  │            │\n",
       "├──────────────────────────────────────────────────┼─────────────────────────────────────────────────┼────────────┤\n",
       "│ ### Instruction(명령어):                         │ ### Instruction(명령어):                        │ [1.0, 0.0] │\n",
       "│ 다음 문장에 다섯 개의 동작 동사를 추가합니다.    │ 다음 문장에 다섯 개의 동작 동사를 추가합니다.   │            │\n",
       "│ 잭                                               │ 잭                                              │            │\n",
       "│                                                  │                                                 │            │\n",
       "│ ### Response(응답):Jack went running, Jack said  │ ### Response(응답):: 잭이 노래하는 것을         │            │\n",
       "│ hello, Jack jumped up and down, Jack cried       │ 들었습니다.&lt;/s&gt;                                 │            │\n",
       "│ loudly, Jack danced happily&lt;/s&gt;                  │                                                 │            │\n",
       "├──────────────────────────────────────────────────┼─────────────────────────────────────────────────┼────────────┤\n",
       "│ ### Instruction(명령어):                         │ ### Instruction(명령어):                        │ [1.0, 0.0] │\n",
       "│ 다음 문장에 다섯 개의 동작 동사를 추가합니다.    │ 다음 문장에 다섯 개의 동작 동사를 추가합니다.   │            │\n",
       "│ 잭                                               │ 잭                                              │            │\n",
       "│                                                  │                                                 │            │\n",
       "│ ### Response(응답)::\"잭은 노래하고 있습니다\",    │ ### Response(응답):: 잭이 노래하는 것을         │            │\n",
       "│ \"제이미는 팝콘을 먹습니다\", \"잭은 춤을 추고      │ 들었습니다.&lt;/s&gt;                                 │            │\n",
       "│ 있습니다\".&lt;/s&gt;                                   │                                                 │            │\n",
       "├──────────────────────────────────────────────────┼─────────────────────────────────────────────────┼────────────┤\n",
       "│ ### Instruction(명령어):                         │ ### Instruction(명령어):                        │ [1.0, 0.0] │\n",
       "│ 일반적으로 토마토를 베이스로 한 소스와 함께      │ 일반적으로 토마토를 베이스로 한 소스와 함께     │            │\n",
       "│ 제공되는 파스타의 한 종류를 말하세요.            │ 제공되는 파스타의 한 종류를 말하세요.           │            │\n",
       "│                                                  │                                                 │            │\n",
       "│ ### Response(응답):\"스파게티\"&lt;/s&gt;                │ ### Response(응답):토마토 소스                  │            │\n",
       "│                                                  │ 파스타입니다.&lt;/s&gt;                               │            │\n",
       "└──────────────────────────────────────────────────┴─────────────────────────────────────────────────┴────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mchosen_text                                     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mrejected_text                                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mlogits    \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│ ### Instruction(명령어):                         │ ### Instruction(명령어):                        │ [1.0, 0.0] │\n",
       "│ 다음 문장에 다섯 개의 동작 동사를 추가합니다.    │ 다음 문장에 다섯 개의 동작 동사를 추가합니다.   │            │\n",
       "│ 잭                                               │ 잭                                              │            │\n",
       "│                                                  │                                                 │            │\n",
       "│ ### Response(응답):Jack went running, Jack said  │ ### Response(응답)::\"잭은 노래하고 있습니다\",   │            │\n",
       "│ hello, Jack jumped up and down, Jack cried       │ \"제이미는 팝콘을 먹습니다\", \"잭은 춤을 추고     │            │\n",
       "│ loudly, Jack danced happily</s>                  │ 있습니다\".</s>                                  │            │\n",
       "├──────────────────────────────────────────────────┼─────────────────────────────────────────────────┼────────────┤\n",
       "│ ### Instruction(명령어):                         │ ### Instruction(명령어):                        │ [1.0, 0.0] │\n",
       "│ 다음 문장에 다섯 개의 동작 동사를 추가합니다.    │ 다음 문장에 다섯 개의 동작 동사를 추가합니다.   │            │\n",
       "│ 잭                                               │ 잭                                              │            │\n",
       "│                                                  │                                                 │            │\n",
       "│ ### Response(응답):Jack went running, Jack said  │ ### Response(응답):: 잭이 노래하는 것을         │            │\n",
       "│ hello, Jack jumped up and down, Jack cried       │ 들었습니다.</s>                                 │            │\n",
       "│ loudly, Jack danced happily</s>                  │                                                 │            │\n",
       "├──────────────────────────────────────────────────┼─────────────────────────────────────────────────┼────────────┤\n",
       "│ ### Instruction(명령어):                         │ ### Instruction(명령어):                        │ [1.0, 0.0] │\n",
       "│ 다음 문장에 다섯 개의 동작 동사를 추가합니다.    │ 다음 문장에 다섯 개의 동작 동사를 추가합니다.   │            │\n",
       "│ 잭                                               │ 잭                                              │            │\n",
       "│                                                  │                                                 │            │\n",
       "│ ### Response(응답)::\"잭은 노래하고 있습니다\",    │ ### Response(응답):: 잭이 노래하는 것을         │            │\n",
       "│ \"제이미는 팝콘을 먹습니다\", \"잭은 춤을 추고      │ 들었습니다.</s>                                 │            │\n",
       "│ 있습니다\".</s>                                   │                                                 │            │\n",
       "├──────────────────────────────────────────────────┼─────────────────────────────────────────────────┼────────────┤\n",
       "│ ### Instruction(명령어):                         │ ### Instruction(명령어):                        │ [1.0, 0.0] │\n",
       "│ 일반적으로 토마토를 베이스로 한 소스와 함께      │ 일반적으로 토마토를 베이스로 한 소스와 함께     │            │\n",
       "│ 제공되는 파스타의 한 종류를 말하세요.            │ 제공되는 파스타의 한 종류를 말하세요.           │            │\n",
       "│                                                  │                                                 │            │\n",
       "│ ### Response(응답):\"스파게티\"</s>                │ ### Response(응답):토마토 소스                  │            │\n",
       "│                                                  │ 파스타입니다.</s>                               │            │\n",
       "└──────────────────────────────────────────────────┴─────────────────────────────────────────────────┴────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> chosen_text                                      </span>┃<span style=\"font-weight: bold\"> rejected_text                                   </span>┃<span style=\"font-weight: bold\"> logits     </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━┩\n",
       "│ ### Instruction(명령어):                         │ ### Instruction(명령어):                        │ [1.0, 0.0] │\n",
       "│ 다음 문장에 다섯 개의 동작 동사를 추가합니다.    │ 다음 문장에 다섯 개의 동작 동사를 추가합니다.   │            │\n",
       "│ 잭                                               │ 잭                                              │            │\n",
       "│                                                  │                                                 │            │\n",
       "│ ### Response(응답):Jack went running, Jack said  │ ### Response(응답)::\"잭은 노래하고 있습니다\",   │            │\n",
       "│ hello, Jack jumped up and down, Jack cried       │ \"제이미는 팝콘을 먹습니다\", \"잭은 춤을 추고     │            │\n",
       "│ loudly, Jack danced happily&lt;/s&gt;                  │ 있습니다\".&lt;/s&gt;                                  │            │\n",
       "├──────────────────────────────────────────────────┼─────────────────────────────────────────────────┼────────────┤\n",
       "│ ### Instruction(명령어):                         │ ### Instruction(명령어):                        │ [1.0, 0.0] │\n",
       "│ 다음 문장에 다섯 개의 동작 동사를 추가합니다.    │ 다음 문장에 다섯 개의 동작 동사를 추가합니다.   │            │\n",
       "│ 잭                                               │ 잭                                              │            │\n",
       "│                                                  │                                                 │            │\n",
       "│ ### Response(응답):Jack went running, Jack said  │ ### Response(응답):: 잭이 노래하는 것을         │            │\n",
       "│ hello, Jack jumped up and down, Jack cried       │ 들었습니다.&lt;/s&gt;                                 │            │\n",
       "│ loudly, Jack danced happily&lt;/s&gt;                  │                                                 │            │\n",
       "├──────────────────────────────────────────────────┼─────────────────────────────────────────────────┼────────────┤\n",
       "│ ### Instruction(명령어):                         │ ### Instruction(명령어):                        │ [1.0, 0.0] │\n",
       "│ 다음 문장에 다섯 개의 동작 동사를 추가합니다.    │ 다음 문장에 다섯 개의 동작 동사를 추가합니다.   │            │\n",
       "│ 잭                                               │ 잭                                              │            │\n",
       "│                                                  │                                                 │            │\n",
       "│ ### Response(응답)::\"잭은 노래하고 있습니다\",    │ ### Response(응답):: 잭이 노래하는 것을         │            │\n",
       "│ \"제이미는 팝콘을 먹습니다\", \"잭은 춤을 추고      │ 들었습니다.&lt;/s&gt;                                 │            │\n",
       "│ 있습니다\".&lt;/s&gt;                                   │                                                 │            │\n",
       "├──────────────────────────────────────────────────┼─────────────────────────────────────────────────┼────────────┤\n",
       "│ ### Instruction(명령어):                         │ ### Instruction(명령어):                        │ [1.0, 0.0] │\n",
       "│ 일반적으로 토마토를 베이스로 한 소스와 함께      │ 일반적으로 토마토를 베이스로 한 소스와 함께     │            │\n",
       "│ 제공되는 파스타의 한 종류를 말하세요.            │ 제공되는 파스타의 한 종류를 말하세요.           │            │\n",
       "│                                                  │                                                 │            │\n",
       "│ ### Response(응답):\"스파게티\"&lt;/s&gt;                │ ### Response(응답):토마토 소스                  │            │\n",
       "│                                                  │ 파스타입니다.&lt;/s&gt;                               │            │\n",
       "└──────────────────────────────────────────────────┴─────────────────────────────────────────────────┴────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TrainOutput(global_step=630, training_loss=1.9338672501700265, metrics={'train_runtime': 2221.3567, 'train_samples_per_second': 18.09, 'train_steps_per_second': 0.284, 'total_flos': 0.0, 'train_loss': 1.9338672501700265, 'epoch': 3.0})"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model = rm_model.merge_and_unload()"
   ],
   "metadata": {},
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(model)"
   ],
   "metadata": {},
   "execution_count": 22,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "GPTRewardModel(\n",
      "  (backbone): GPT2Model(\n",
      "    (wte): Embedding(51200, 1920)\n",
      "    (wpe): Embedding(1024, 1920)\n",
      "    (drop): Dropout(p=0, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-23): 24 x GPT2Block(\n",
      "        (ln_1): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D(nf=5760, nx=1920)\n",
      "          (c_proj): Conv1D(nf=1920, nx=1920)\n",
      "          (attn_dropout): Dropout(p=0, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D(nf=7680, nx=1920)\n",
      "          (c_proj): Conv1D(nf=1920, nx=7680)\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((1920,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (v_head): Linear(in_features=1920, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model.backbone.save_pretrained(\"/content/drive/MyDrive/rm_backbone\")\n",
    "torch.save(model.v_head.state_dict(), \"/content/drive/MyDrive/rm_backbone/v_head.bin\")"
   ],
   "metadata": {},
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model_test = GPTRewardModel(model_path=\"/content/drive/MyDrive/rm_backbone\")"
   ],
   "metadata": {},
   "execution_count": 24,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "v_head_weights = torch.load(\"/content/drive/MyDrive/rm_backbone/v_head.bin\", map_location=\"cpu\")\n",
    "model_test.v_head.load_state_dict(v_head_weights)"
   ],
   "metadata": {},
   "execution_count": 25,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ]
  }
 ]
}